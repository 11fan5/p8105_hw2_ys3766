p8105_hw2_ys3766
================
Yifan Shi
2024-10-02

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

### Problem 1

Importing data, cleaning data, selecting variables

``` r
transit = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11= "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, entry, exit_only, vending, entrance_type, ada,
    starts_with("route")
  ) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The resulting data set contains 1868 observations of 20 variables now.
It has variables on NYC subway lines, stations, location of the station,
entry and exit information, vending, ADA compliance information and
routes.I cleaned the data by converting column types of route8-route11,
cleaning the names of the variables, selecting relevant variables, and
converting the entry variable to logical. I would say the dataset is not
yet tidy, as the route variables is currently wide format. To further
tidy the data set, I would convert the route variables from wide to long
format, and create a new “route number” variable.

Number of distinct stations

``` r
transit %>% 
 distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 465

There are 465 distinct stations.

ADA compliant stations

``` r
transit %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 84

There are 84 ADA compliant stations.

Proportion of station entrances/exits without vending allow entrance

``` r
transit %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean()
```

    ## [1] 0.3770492

37.7% of station entrances/exits without vending allow entrance

Reformat the data so that route number and route name are distinct
variables

``` r
transit<-transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route"
  )
```

Distinct stations serve the A train, how many ADA compliant

``` r
transit %>% 
  filter(route == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 60

``` r
transit %>% 
  filter(route == "A", ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 17

There are 60 distinct stations serving the A train, of which 17 are ADA
compliant.

### Problem 2

import and tidy the sheet Mr Trash Wheel

``` r
mr_trash_wheel = 
  read_excel('data/202409 Trash Wheel Collection Data.xlsx', 
             sheet = 'Mr. Trash Wheel',
             range = cell_cols("A:N"),
             skip = 1,
             ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)),
         year = as.numeric(year))
```

import and tidy the sheet Professor Trash Wheel

``` r
prof_trash_wheel = 
  read_excel('data/202409 Trash Wheel Collection Data.xlsx', 
             sheet = 'Professor Trash Wheel',
             range = cell_cols("A:M"),
             skip = 1,
             ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster))
```

import and tidy the sheet Gwynnda Trash Wheel

``` r
gwynnda_trash_wheel = 
  read_excel('data/202409 Trash Wheel Collection Data.xlsx', 
             sheet = 'Gwynnda Trash Wheel',
             range = cell_cols("A:L"),
             skip = 1,
             ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) 
```

Create an indicator variable for the sourse, then combine the 3
individual df to produce a single df

``` r
mr_trash_wheel<- mr_trash_wheel %>% 
  mutate(source = "Mr. Trash Wheel")

prof_trash_wheel<- prof_trash_wheel %>% 
  mutate(source = "Professor Trash Wheel")

gwynnda_trash_wheel <- gwynnda_trash_wheel %>% 
  mutate(source = "Gwynnda Trash Wheel")

trash_wheel <- bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) %>% 
  relocate(source)
```

Total weight of trash collected by professor trash wheel

``` r
trash_wheel %>% 
  filter(source == "Professor Trash Wheel") %>% 
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) %>% 
  pull(total_weight)
```

    ## [1] 246.74

Total number of cigarette butts collected by Gwynnda in june 2022

``` r
trash_wheel %>% 
  filter(source == "Gwynnda Trash Wheel", month == "June", year == 2022) %>% 
  summarise(total_cig = sum(cigarette_butts, na.rm = TRUE)) %>% 
  pull(total_cig)
```

    ## [1] 18120

The combined dataset consists of 1033 observations of 15 variables,
spanning multiple years and encompassing data from the 3 trash wheels,
namely the Mr. Trash Wheel, Professor Trash Wheel, and Gwynnd Trash
Wheel. It has variables on dumpter number, date of collection, amount of
total litter and litter type.

The total weight of trash collected by Professor Trash Wheel was 246.74
tons. The total number of cigarette butts collected by Gwynnda in June
of 2022 was 18120.

### Problem 3

Import and tidy data

``` r
bakers = 
  read_csv('data/bakers.csv') %>% 
  janitor::clean_names() %>% 
  separate(baker_name, into = c("baker", "baker_last_name"), sep = " ", extra = "merge") 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes = 
  read_csv('data/bakes.csv', na = c("NA", " ", ".", "UNKNOWN", "Unknown", "N/A")) %>% 
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results =
  read_csv('data/results.csv', skip = 2) %>% 
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Check for completeness and correctness

``` r
anti_join(bakes, bakers, by = c("series","baker"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… <NA>        
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(results, bakers, by = c("series","baker"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

The mismatched records are displayed in the output table of anti_join.

merging datasets, arrange the final dataset

``` r
merged_data <- bakers %>%
  inner_join(bakes, by = c("baker", "series")) %>%
  inner_join(results, by = c("baker", "series", "episode")) %>%
  select(baker, baker_last_name, baker_age, baker_occupation, hometown,
          series, episode, signature_bake, show_stopper, technical, result)
write_csv(merged_data, "data/merged_data.csv")
```

I clean the data by first importing and viewing each individual dataset.
I cleaned the column names into consistent format. For the bakers
dataset, I separated baker_name into baker and baker_last_name, so that
it is consistent with other datasets. For the bakes dataset, I specified
a wide array of potential NA indicators after glancing through the
dataset. For the result dataset, I skipped the first two rows when
loading.

When merging the three data sets into a single one, I was not sure if i
should keep bakers who did not appear in a certain data set. I was not
sure whether to use full_join, inner_join or left_join, and how
complete/comprehensive I want the final dataset to be. In the end, I
decided to use inner_join and kept all rows in the bakers dataset, so
that the final data set is as complete as possible, in case certain
information is needed.

The final dataset contains all bakers that are in the bakers dataset,
with their demographics, series and epidose, their bake, show stopper,
technical and final results. I arranged the columns by fist the
demographics (name, age, occupation, hometown), then the show contexts
(series, episode), baking details (signature bakes, show stopper), then
performance metrics (technical, result).

The viewer data set, pivot longer

``` r
viewers = 
  read_csv('data/viewers.csv') %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = starts_with("series"),
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
  )
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series viewers
    ##      <dbl> <chr>    <dbl>
    ##  1       1 1         2.24
    ##  2       1 2         3.1 
    ##  3       1 3         3.85
    ##  4       1 4         6.6 
    ##  5       1 5         8.51
    ##  6       1 6        11.6 
    ##  7       1 7        13.6 
    ##  8       1 8         9.46
    ##  9       1 9         9.55
    ## 10       1 10        9.62

average viewership

``` r
viewers %>% 
  filter(series == 1) %>% 
  summarise(average_1 = mean(viewers, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   average_1
    ##       <dbl>
    ## 1      2.77

``` r
viewers %>% 
  filter(series == 5) %>% 
  summarise(average_5 = mean(viewers, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   average_5
    ##       <dbl>
    ## 1      10.0

The average viewership in season 1 was 2.77, and the average viewership
in season 5 was 10.0.
